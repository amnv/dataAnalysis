{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/allyson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise exploratória dos dados\n",
    "Inicialmente iremos observar algumas informações iniciais sobre a base de dados. Com base em pesquisas sobe a base de dados consegui descobrir algumas informações interessantes.\n",
    "\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "\n",
    "1 - somewhat negative\n",
    "\n",
    "2 - neutral\n",
    "\n",
    "3 - somewhat positive\n",
    "\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dados/train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4079.732744</td>\n",
       "      <td>2.063578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45050.785842</td>\n",
       "      <td>2502.764394</td>\n",
       "      <td>0.893832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39015.750000</td>\n",
       "      <td>1861.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4017.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>117045.250000</td>\n",
       "      <td>6244.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>8544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id     IdSentenca     Sentimento\n",
       "count  156060.000000  156060.000000  156060.000000\n",
       "mean   78030.500000   4079.732744    2.063578     \n",
       "std    45050.785842   2502.764394    0.893832     \n",
       "min    1.000000       1.000000       0.000000     \n",
       "25%    39015.750000   1861.750000    2.000000     \n",
       "50%    78030.500000   4017.000000    2.000000     \n",
       "75%    117045.250000  6244.000000    3.000000     \n",
       "max    156060.000000  8544.000000    4.000000     "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>the adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>good for the goose</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>is also</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156030</th>\n",
       "      <td>156031</td>\n",
       "      <td>8542</td>\n",
       "      <td>a joke in the United States</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156031</th>\n",
       "      <td>156032</td>\n",
       "      <td>8543</td>\n",
       "      <td>The movie 's downfall is to substitute plot for personality .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156032</th>\n",
       "      <td>156033</td>\n",
       "      <td>8543</td>\n",
       "      <td>The movie 's downfall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156033</th>\n",
       "      <td>156034</td>\n",
       "      <td>8543</td>\n",
       "      <td>is to substitute plot for personality .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156034</th>\n",
       "      <td>156035</td>\n",
       "      <td>8543</td>\n",
       "      <td>is to substitute plot for personality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156035</th>\n",
       "      <td>156036</td>\n",
       "      <td>8543</td>\n",
       "      <td>to substitute plot for personality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156036</th>\n",
       "      <td>156037</td>\n",
       "      <td>8543</td>\n",
       "      <td>substitute plot for personality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156037</th>\n",
       "      <td>156038</td>\n",
       "      <td>8543</td>\n",
       "      <td>substitute plot</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156038</th>\n",
       "      <td>156039</td>\n",
       "      <td>8543</td>\n",
       "      <td>for personality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156039</th>\n",
       "      <td>156040</td>\n",
       "      <td>8544</td>\n",
       "      <td>The film is darkly atmospheric , with Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156040</th>\n",
       "      <td>156041</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric , with Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156041</th>\n",
       "      <td>156042</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric , with Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156042</th>\n",
       "      <td>156043</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric ,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156043</th>\n",
       "      <td>156044</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156044</th>\n",
       "      <td>156045</td>\n",
       "      <td>8544</td>\n",
       "      <td>with Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156045</th>\n",
       "      <td>156046</td>\n",
       "      <td>8544</td>\n",
       "      <td>Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156046</th>\n",
       "      <td>156047</td>\n",
       "      <td>8544</td>\n",
       "      <td>Herrmann</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156047</th>\n",
       "      <td>156048</td>\n",
       "      <td>8544</td>\n",
       "      <td>quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156048</th>\n",
       "      <td>156049</td>\n",
       "      <td>8544</td>\n",
       "      <td>suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156049</th>\n",
       "      <td>156050</td>\n",
       "      <td>8544</td>\n",
       "      <td>suggesting the sadness and obsession</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156050</th>\n",
       "      <td>156051</td>\n",
       "      <td>8544</td>\n",
       "      <td>the sadness and obsession</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156051</th>\n",
       "      <td>156052</td>\n",
       "      <td>8544</td>\n",
       "      <td>sadness and obsession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156052</th>\n",
       "      <td>156053</td>\n",
       "      <td>8544</td>\n",
       "      <td>sadness and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156053</th>\n",
       "      <td>156054</td>\n",
       "      <td>8544</td>\n",
       "      <td>beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156054</th>\n",
       "      <td>156055</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  IdSentenca  \\\n",
       "0       1       1            \n",
       "1       2       1            \n",
       "2       3       1            \n",
       "3       4       1            \n",
       "4       5       1            \n",
       "5       6       1            \n",
       "6       7       1            \n",
       "7       8       1            \n",
       "8       9       1            \n",
       "9       10      1            \n",
       "10      11      1            \n",
       "11      12      1            \n",
       "12      13      1            \n",
       "13      14      1            \n",
       "14      15      1            \n",
       "15      16      1            \n",
       "16      17      1            \n",
       "17      18      1            \n",
       "18      19      1            \n",
       "19      20      1            \n",
       "20      21      1            \n",
       "21      22      1            \n",
       "22      23      1            \n",
       "23      24      1            \n",
       "24      25      1            \n",
       "25      26      1            \n",
       "26      27      1            \n",
       "27      28      1            \n",
       "28      29      1            \n",
       "29      30      1            \n",
       "...     ..     ..            \n",
       "156030  156031  8542         \n",
       "156031  156032  8543         \n",
       "156032  156033  8543         \n",
       "156033  156034  8543         \n",
       "156034  156035  8543         \n",
       "156035  156036  8543         \n",
       "156036  156037  8543         \n",
       "156037  156038  8543         \n",
       "156038  156039  8543         \n",
       "156039  156040  8544         \n",
       "156040  156041  8544         \n",
       "156041  156042  8544         \n",
       "156042  156043  8544         \n",
       "156043  156044  8544         \n",
       "156044  156045  8544         \n",
       "156045  156046  8544         \n",
       "156046  156047  8544         \n",
       "156047  156048  8544         \n",
       "156048  156049  8544         \n",
       "156049  156050  8544         \n",
       "156050  156051  8544         \n",
       "156051  156052  8544         \n",
       "156052  156053  8544         \n",
       "156053  156054  8544         \n",
       "156054  156055  8544         \n",
       "156055  156056  8544         \n",
       "156056  156057  8544         \n",
       "156057  156058  8544         \n",
       "156058  156059  8544         \n",
       "156059  156060  8544         \n",
       "\n",
       "                                                                                                                                                                                               Texto  \\\n",
       "0       A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .   \n",
       "1       A series of escapades demonstrating the adage that what is good for the goose                                                                                                                  \n",
       "2       A series                                                                                                                                                                                       \n",
       "3       A                                                                                                                                                                                              \n",
       "4       series                                                                                                                                                                                         \n",
       "5       of escapades demonstrating the adage that what is good for the goose                                                                                                                           \n",
       "6       of                                                                                                                                                                                             \n",
       "7       escapades demonstrating the adage that what is good for the goose                                                                                                                              \n",
       "8       escapades                                                                                                                                                                                      \n",
       "9       demonstrating the adage that what is good for the goose                                                                                                                                        \n",
       "10      demonstrating the adage                                                                                                                                                                        \n",
       "11      demonstrating                                                                                                                                                                                  \n",
       "12      the adage                                                                                                                                                                                      \n",
       "13      the                                                                                                                                                                                            \n",
       "14      adage                                                                                                                                                                                          \n",
       "15      that what is good for the goose                                                                                                                                                                \n",
       "16      that                                                                                                                                                                                           \n",
       "17      what is good for the goose                                                                                                                                                                     \n",
       "18      what                                                                                                                                                                                           \n",
       "19      is good for the goose                                                                                                                                                                          \n",
       "20      is                                                                                                                                                                                             \n",
       "21      good for the goose                                                                                                                                                                             \n",
       "22      good                                                                                                                                                                                           \n",
       "23      for the goose                                                                                                                                                                                  \n",
       "24      for                                                                                                                                                                                            \n",
       "25      the goose                                                                                                                                                                                      \n",
       "26      goose                                                                                                                                                                                          \n",
       "27      is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .                                                                                 \n",
       "28      is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story                                                                                   \n",
       "29      is also                                                                                                                                                                                        \n",
       "...         ...                                                                                                                                                                                        \n",
       "156030  a joke in the United States                                                                                                                                                                    \n",
       "156031  The movie 's downfall is to substitute plot for personality .                                                                                                                                  \n",
       "156032  The movie 's downfall                                                                                                                                                                          \n",
       "156033  is to substitute plot for personality .                                                                                                                                                        \n",
       "156034  is to substitute plot for personality                                                                                                                                                          \n",
       "156035  to substitute plot for personality                                                                                                                                                             \n",
       "156036  substitute plot for personality                                                                                                                                                                \n",
       "156037  substitute plot                                                                                                                                                                                \n",
       "156038  for personality                                                                                                                                                                                \n",
       "156039  The film is darkly atmospheric , with Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles .                                                      \n",
       "156040  is darkly atmospheric , with Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles .                                                               \n",
       "156041  is darkly atmospheric , with Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles                                                                 \n",
       "156042  is darkly atmospheric ,                                                                                                                                                                        \n",
       "156043  is darkly atmospheric                                                                                                                                                                          \n",
       "156044  with Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles                                                                                         \n",
       "156045  Herrmann quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles                                                                                              \n",
       "156046  Herrmann                                                                                                                                                                                       \n",
       "156047  quietly suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles                                                                                                       \n",
       "156048  suggesting the sadness and obsession beneath Hearst 's forced avuncular chortles                                                                                                               \n",
       "156049  suggesting the sadness and obsession                                                                                                                                                           \n",
       "156050  the sadness and obsession                                                                                                                                                                      \n",
       "156051  sadness and obsession                                                                                                                                                                          \n",
       "156052  sadness and                                                                                                                                                                                    \n",
       "156053  beneath Hearst 's forced avuncular chortles                                                                                                                                                    \n",
       "156054  Hearst 's forced avuncular chortles                                                                                                                                                            \n",
       "156055  Hearst 's                                                                                                                                                                                      \n",
       "156056  forced avuncular chortles                                                                                                                                                                      \n",
       "156057  avuncular chortles                                                                                                                                                                             \n",
       "156058  avuncular                                                                                                                                                                                      \n",
       "156059  chortles                                                                                                                                                                                       \n",
       "\n",
       "        Sentimento  \n",
       "0       1           \n",
       "1       2           \n",
       "2       2           \n",
       "3       2           \n",
       "4       2           \n",
       "5       2           \n",
       "6       2           \n",
       "7       2           \n",
       "8       2           \n",
       "9       2           \n",
       "10      2           \n",
       "11      2           \n",
       "12      2           \n",
       "13      2           \n",
       "14      2           \n",
       "15      2           \n",
       "16      2           \n",
       "17      2           \n",
       "18      2           \n",
       "19      2           \n",
       "20      2           \n",
       "21      3           \n",
       "22      3           \n",
       "23      2           \n",
       "24      2           \n",
       "25      2           \n",
       "26      2           \n",
       "27      2           \n",
       "28      2           \n",
       "29      2           \n",
       "...    ..           \n",
       "156030  2           \n",
       "156031  1           \n",
       "156032  1           \n",
       "156033  1           \n",
       "156034  1           \n",
       "156035  2           \n",
       "156036  1           \n",
       "156037  2           \n",
       "156038  2           \n",
       "156039  2           \n",
       "156040  2           \n",
       "156041  2           \n",
       "156042  2           \n",
       "156043  3           \n",
       "156044  2           \n",
       "156045  2           \n",
       "156046  2           \n",
       "156047  1           \n",
       "156048  2           \n",
       "156049  2           \n",
       "156050  2           \n",
       "156051  1           \n",
       "156052  1           \n",
       "156053  2           \n",
       "156054  2           \n",
       "156055  2           \n",
       "156056  1           \n",
       "156057  3           \n",
       "156058  2           \n",
       "156059  2           \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sentimento = pd.Categorical(df.Sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff0e337dbe0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFbVJREFUeJzt3X+MXfWZ3/H3J/aSkG0JJhhEbbpmFSsJYRsCI3AbqcqG1AykivkjSNDV2kJup41MN2krdclWlXeTICVSVVqkhMoKDna0G4fQjbB2nbiWCbvabUI8JBRiHOoJycLUBGbXhrBlE9bk6R/36/rK5w5zZ2x8h/j9kq7uOc95zpnvvZj5zPlx70lVIUlSvzeMegCSpMXHcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpY+moB7BQ559/fq1atWrUw5Ck142HH374L6tq+TC9r9twWLVqFZOTk6MehiS9biT5i2F7PawkSeowHCRJHYaDJKnDcJAkdQwVDkn+TZL9Sb6X5EtJ3pTkkiQPJTmY5MtJzmq9b2zzU235qr7tfLzVn0hybV99vNWmktx2ql+kJGl+5gyHJCuA3wLGquoyYAlwE/AZ4I6qWg0cATa2VTYCR6rqbcAdrY8kl7b13gWMA59LsiTJEuCzwHXApcDNrVeSNCLDHlZaCpydZCnwZuAZ4P3AfW35NuCGNr2uzdOWX5Mkrb6jqn5WVT8EpoCr2mOqqp6sqpeBHa1XkjQic4ZDVf0f4D8BT9ELhReAh4Hnq+poa5sGVrTpFcDTbd2jrf+t/fUT1pmt3pFkIslkksmZmZlhXp8kaQHm/BBckmX0/pK/BHge+Aq9Q0AnOnYz6syybLb6oIAaeGPrqtoCbAEYGxs7qZtfr7rtj09m9VPmR5/+4KiHIEkdwxxW+gDww6qaqaq/Bf4Q+EfAue0wE8BK4FCbngYuBmjL3wIc7q+fsM5sdUnSiAwTDk8Ba5K8uZ07uAZ4HPgG8OHWswG4v03vbPO05Q9UVbX6Te1qpkuA1cC3gX3A6nb101n0TlrvPPmXJklaqDkPK1XVQ0nuA74DHAW+S+/Qzh8DO5J8qtXubqvcDXwxyRS9PYab2nb2J7mXXrAcBTZV1SsASW4FdtO7EmprVe0/dS9RkjRfQ33xXlVtBjafUH6S3pVGJ/b+FLhxlu3cDtw+oL4L2DXMWCRJrz0/IS1J6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqmDMckrw9ySN9j58k+ViS85LsSXKwPS9r/UlyZ5KpJI8muaJvWxta/8EkG/rqVyZ5rK1zZ7tXtSRpROYMh6p6oqour6rLgSuBl4CvArcBe6tqNbC3zQNcB6xujwngLoAk59G71ejV9G4vuvlYoLSeib71xk/Jq5MkLch8DytdA/ygqv4CWAdsa/VtwA1teh2wvXq+BZyb5CLgWmBPVR2uqiPAHmC8LTunqr5ZVQVs79uWJGkE5hsONwFfatMXVtUzAO35glZfATzdt850q71afXpAvSPJRJLJJJMzMzPzHLokaVhDh0OSs4APAV+Zq3VArRZQ7xartlTVWFWNLV++fI5hSJIWaj57DtcB36mqZ9v8s+2QEO35uVafBi7uW28lcGiO+soBdUnSiMwnHG7m+CElgJ3AsSuONgD399XXt6uW1gAvtMNOu4G1SZa1E9Frgd1t2YtJ1rSrlNb3bUuSNAJLh2lK8mbgnwD/sq/8aeDeJBuBp4AbW30XcD0wRe/KplsAqupwkk8C+1rfJ6rqcJv+CHAPcDbwtfaQJI3IUOFQVS8Bbz2h9lf0rl46sbeATbNsZyuwdUB9ErhsmLFIkl57fkJaktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1DFUOCQ5N8l9Sb6f5ECSf5jkvCR7khxsz8tab5LcmWQqyaNJrujbzobWfzDJhr76lUkea+vc2e4lLUkakWH3HP4r8PWqegfwbuAAcBuwt6pWA3vbPMB1wOr2mADuAkhyHrAZuBq4Cth8LFBaz0TfeuMn97IkSSdjznBIcg7wj4G7Aarq5ap6HlgHbGtt24Ab2vQ6YHv1fAs4N8lFwLXAnqo6XFVHgD3AeFt2TlV9s91/envftiRJIzDMnsOvAjPAF5J8N8nnk/wycGFVPQPQni9o/SuAp/vWn261V6tPD6h3JJlIMplkcmZmZoihS5IWYphwWApcAdxVVe8B/i/HDyENMuh8QS2g3i1WbamqsaoaW758+auPWpK0YMOEwzQwXVUPtfn76IXFs+2QEO35ub7+i/vWXwkcmqO+ckBdkjQic4ZDVf0YeDrJ21vpGuBxYCdw7IqjDcD9bXonsL5dtbQGeKEddtoNrE2yrJ2IXgvsbsteTLKmXaW0vm9bkqQRWDpk378Gfj/JWcCTwC30guXeJBuBp4AbW+8u4HpgCnip9VJVh5N8EtjX+j5RVYfb9EeAe4Czga+1hyRpRIYKh6p6BBgbsOiaAb0FbJplO1uBrQPqk8Blw4xFkvTa8xPSkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpI6hwiHJj5I8luSRJJOtdl6SPUkOtudlrZ4kdyaZSvJokiv6trOh9R9MsqGvfmXb/lRbN6f6hUqShjefPYdfr6rLq+rY7UJvA/ZW1Wpgb5sHuA5Y3R4TwF3QCxNgM3A1cBWw+VigtJ6JvvXGF/yKJEkn7WQOK60DtrXpbcANffXt1fMt4NwkFwHXAnuq6nBVHQH2AONt2TlV9c12/+ntfduSJI3AsOFQwP9I8nCSiVa7sKqeAWjPF7T6CuDpvnWnW+3V6tMD6h1JJpJMJpmcmZkZcuiSpPlaOmTfe6vqUJILgD1Jvv8qvYPOF9QC6t1i1RZgC8DY2NjAHknSyRtqz6GqDrXn54Cv0jtn8Gw7JER7fq61TwMX962+Ejg0R33lgLokaUTmDIckv5zk7x6bBtYC3wN2AseuONoA3N+mdwLr21VLa4AX2mGn3cDaJMvaiei1wO627MUka9pVSuv7tiVJGoFhDitdCHy1XV26FPiDqvp6kn3AvUk2Ak8BN7b+XcD1wBTwEnALQFUdTvJJYF/r+0RVHW7THwHuAc4GvtYekqQRmTMcqupJ4N0D6n8FXDOgXsCmWba1Fdg6oD4JXDbEeCVJp4GfkJYkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1DB0OSZYk+W6SP2rzlyR5KMnBJF9Oclarv7HNT7Xlq/q28fFWfyLJtX318VabSnLbqXt5kqSFmM+ew0eBA33znwHuqKrVwBFgY6tvBI5U1duAO1ofSS4FbgLeBYwDn2uBswT4LHAdcClwc+uVJI3IUOGQZCXwQeDzbT7A+4H7Wss24IY2va7N05Zf0/rXATuq6mdV9UNgCriqPaaq6smqehnY0XolSSMy7J7DfwH+PfDzNv9W4PmqOtrmp4EVbXoF8DRAW/5C6///9RPWma3ekWQiyWSSyZmZmSGHLkmarznDIck/BZ6rqof7ywNaa45l8613i1VbqmqsqsaWL1/+KqOWJJ2MpUP0vBf4UJLrgTcB59Dbkzg3ydK2d7ASONT6p4GLgekkS4G3AIf76sf0rzNbXZI0AnPuOVTVx6tqZVWtondC+YGq+g3gG8CHW9sG4P42vbPN05Y/UFXV6je1q5kuAVYD3wb2Aavb1U9ntZ+x85S8OknSggyz5zCb3wZ2JPkU8F3g7la/G/hikil6eww3AVTV/iT3Ao8DR4FNVfUKQJJbgd3AEmBrVe0/iXFJkk7SvMKhqh4EHmzTT9K70ujEnp8CN86y/u3A7QPqu4Bd8xmLJOm14yekJUkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1HEyX9mtXxS/+5ZRj6Dnd18Y9QgkNe45SJI6DAdJUofhIEnqmDMckrwpybeT/K8k+5P8XqtfkuShJAeTfLnd/5l2j+gvJ5lqy1f1bevjrf5Ekmv76uOtNpXktlP/MiVJ8zHMnsPPgPdX1buBy4HxJGuAzwB3VNVq4AiwsfVvBI5U1duAO1ofSS6ldz/pdwHjwOeSLEmyBPgscB1wKXBz65Ukjcic4VA9f91mf6k9Cng/cF+rbwNuaNPr2jxt+TVJ0uo7qupnVfVDYIrePaivAqaq6smqehnY0XolSSMy1DmH9hf+I8BzwB7gB8DzVXW0tUwDK9r0CuBpgLb8BeCt/fUT1pmtPmgcE0kmk0zOzMwMM3RJ0gIMFQ5V9UpVXQ6spPeX/jsHtbXnzLJsvvVB49hSVWNVNbZ8+fK5By5JWpB5Xa1UVc8DDwJrgHOTHPsQ3UrgUJueBi4GaMvfAhzur5+wzmx1SdKIDHO10vIk57bps4EPAAeAbwAfbm0bgPvb9M42T1v+QFVVq9/Urma6BFgNfBvYB6xuVz+dRe+k9c5T8eIkSQszzNdnXARsa1cVvQG4t6r+KMnjwI4knwK+C9zd+u8Gvphkit4ew00AVbU/yb3A48BRYFNVvQKQ5FZgN7AE2FpV+0/ZK5Qkzduc4VBVjwLvGVB/kt75hxPrPwVunGVbtwO3D6jvAnYNMV5J0mngJ6QlSR1+K6vU59e2/dqohwDAYxseG/UQdIZzz0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1DHMP6YuTfCPJgST7k3y01c9LsifJwfa8rNWT5M4kU0keTXJF37Y2tP6DSTb01a9M8lhb584keS1erCRpOMPsORwF/l1VvRNYA2xKcilwG7C3qlYDe9s8wHXA6vaYAO6CXpgAm4Gr6d1edPOxQGk9E33rjZ/8S5MkLdSc4VBVz1TVd9r0i8ABYAWwDtjW2rYBN7TpdcD26vkWcG6Si4BrgT1VdbiqjgB7gPG27Jyq+mZVFbC9b1uSpBGY1zmHJKuA9wAPARdW1TPQCxDggta2Ani6b7XpVnu1+vSA+qCfP5FkMsnkzMzMfIYuSZqHocMhyd8B/jvwsar6yau1DqjVAurdYtWWqhqrqrHly5fPNWRJ0gINFQ5JfoleMPx+Vf1hKz/bDgnRnp9r9Wng4r7VVwKH5qivHFCXJI3IMFcrBbgbOFBV/7lv0U7g2BVHG4D7++rr21VLa4AX2mGn3cDaJMvaiei1wO627MUka9rPWt+3LUnSCCwdoue9wG8CjyV5pNV+B/g0cG+SjcBTwI1t2S7gemAKeAm4BaCqDif5JLCv9X2iqg636Y8A9wBnA19rD0nSiMwZDlX1Zww+LwBwzYD+AjbNsq2twNYB9UngsrnGIkk6PfyEtCSpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKljmHtIb03yXJLv9dXOS7InycH2vKzVk+TOJFNJHk1yRd86G1r/wSQb+upXJnmsrXNnu4+0JGmEhtlzuAcYP6F2G7C3qlYDe9s8wHXA6vaYAO6CXpgAm4GrgauAzccCpfVM9K134s+SJJ1mc4ZDVf0pcPiE8jpgW5veBtzQV99ePd8Czk1yEXAtsKeqDlfVEWAPMN6WnVNV32z3nt7ety1J0ogs9JzDhVX1DEB7vqDVVwBP9/VNt9qr1acH1AdKMpFkMsnkzMzMAocuSZrLqT4hPeh8QS2gPlBVbamqsaoaW758+QKHKEmay9IFrvdskouq6pl2aOi5Vp8GLu7rWwkcavX3nVB/sNVXDuiXNGIH3vHOUQ8BgHd+/8Coh3BGWuiew07g2BVHG4D7++rr21VLa4AX2mGn3cDaJMvaiei1wO627MUka9pVSuv7tiVJGpE59xySfIneX/3nJ5mmd9XRp4F7k2wEngJubO27gOuBKeAl4BaAqjqc5JPAvtb3iao6dpL7I/SuiDob+Fp7SJJGaM5wqKqbZ1l0zYDeAjbNsp2twNYB9UngsrnGIUk6ffyEtCSpw3CQJHUs9GolSTpjfPZfPTDqIQCw6b+9/7T9LPccJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6Fk04JBlP8kSSqSS3jXo8knQmWxThkGQJ8FngOuBS4OYkl452VJJ05loU4QBcBUxV1ZNV9TKwA1g34jFJ0hkrVTXqMZDkw8B4Vf3zNv+bwNVVdesJfRPARJt9O/DEaR1o1/nAX454DIuF78VxvhfH+V4ctxjei1+pquXDNC6W24RmQK2TWlW1Bdjy2g9nOEkmq2ps1ONYDHwvjvO9OM734rjX23uxWA4rTQMX982vBA6NaCySdMZbLOGwD1id5JIkZwE3ATtHPCZJOmMtisNKVXU0ya3AbmAJsLWq9o94WMNYNIe4FgHfi+N8L47zvTjudfVeLIoT0pKkxWWxHFaSJC0ihoMkqcNwkCR1LIoT0nr9SXIVUFW1r33VyTjw/araNeKhaZFIsr2q1o96HKOS5B30vulhBb3PbR0CdlbVgZEObEiekJ6H9h97BfBQVf11X328qr4+upGdXkk20/serKXAHuBq4EHgA8Duqrp9dKPTKCQ58dLzAL8OPABQVR867YMaoSS/DdxM76uAplt5Jb3L9HdU1adHNbZhGQ5DSvJbwCbgAHA58NGqur8t+05VXTHK8Z1OSR6j9x68EfgxsLKqfpLkbHrB+Q9GOsBFIsktVfWFUY/jdEjyHeBx4PP0/koO8CV6vwypqj8Z3ehOvyT/G3hXVf3tCfWzgP1VtXo0Ixue5xyG9y+AK6vqBuB9wH9M8tG2bNDXf/wiO1pVr1TVS8APquonAFX1N8DPRzu0ReX3Rj2A02gMeBj4D8ALVfUg8DdV9SdnWjA0Pwf+3oD6RbxO/h/xnMPwlhw7lFRVP0ryPuC+JL/CmRcOLyd5cwuHK48Vk7yF18k//FMlyaOzLQIuPJ1jGaWq+jlwR5KvtOdnObN/v3wM2JvkIPB0q/194G3ArbOutYh4WGlISR4A/m1VPdJXWwpsBX6jqpaMbHCnWZI3VtXPBtTPBy6qqsdGMKyRaL8ErwWOnLgI+J9VNeivx194ST4IvLeqfmfUYxmVJG+gdzuCFfT+PUwD+6rqlZEObEiGw5CSrKR3OOXHA5a9t6r+fATD0ogluRv4QlX92YBlf1BV/2wEw5JOmuEgSerwhLQkqcNwkCR1GA6SpA7DQZLU8f8AR37NDrneG1UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff0e337d828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Sentimento.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados para o modelo\n",
    "\n",
    "A seguir serão realizadas etapas de pré-processamento com o objetivo de tornar os dados próprios para os processos de treino e teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.Texto, df.Sentimento, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124848\n",
      "31212\n"
     ]
    }
   ],
   "source": [
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in df:\n",
    "          \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", sent)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)\n",
    "\n",
    "#cleaned reviews for both train and test set retrieved\n",
    "train_sentences = clean_sentences(x_train)\n",
    "test_sentences = clean_sentences(x_test)\n",
    "print(len(train_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(clf, x_train, x_test, y_train, y_test):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"acurácia: \" + str(clf.score(x_test, y_test)))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino e Teste com Naive Bayes\n",
    "\n",
    "Fizemos teste utilizando cross validation e uma divisão usando train_test_split do sklearn. A primeira para ter uma visão mais macro do desempenho do modelo e a seguda para verifcar como cada classe estava sendo avaliada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.6094450852236319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.30      0.35      1454\n",
      "          1       0.49      0.43      0.46      5509\n",
      "          2       0.69      0.77      0.73     15805\n",
      "          3       0.52      0.51      0.51      6570\n",
      "          4       0.49      0.34      0.40      1874\n",
      "\n",
      "avg / total       0.60      0.61      0.60     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_pip = Pipeline([(\"counts\", CountVectorizer()),\n",
    "                      (\"classifier\", MultinomialNB())])\n",
    "report(naive_pip, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allyson/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_precision_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/allyson/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_recall_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.89041686, 1.93228292, 1.8529315 , 2.04551792, 2.02107   ]),\n",
       " 'score_time': array([0.89078188, 1.01947141, 0.98106146, 1.055475  , 1.0290072 ]),\n",
       " 'test_precision_macro': array([0.47224536, 0.42281415, 0.42328417, 0.43829074, 0.46495225]),\n",
       " 'test_recall_macro': array([0.3776469 , 0.37063204, 0.36526491, 0.37338739, 0.38080753]),\n",
       " 'train_precision_macro': array([0.60431679, 0.608656  , 0.60826417, 0.61305397, 0.61116037]),\n",
       " 'train_recall_macro': array([0.55273791, 0.55749974, 0.55267289, 0.55408693, 0.55734441])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = ['precision_macro', 'recall_macro']\n",
    "cross_validate(naive_pip, df.Texto, df.Sentimento, scoring=scoring, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.5848071254645649\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.04      0.07      1454\n",
      "          1       0.52      0.25      0.34      5509\n",
      "          2       0.60      0.90      0.72     15805\n",
      "          3       0.53      0.38      0.45      6570\n",
      "          4       0.62      0.05      0.10      1874\n",
      "\n",
      "avg / total       0.57      0.58      0.53     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_pip2 = Pipeline([(\"counts\", TfidfVectorizer()),\n",
    "                      (\"classifier\", MultinomialNB())])\n",
    "report(naive_pip2, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.5739138792772011\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.48      0.40      1440\n",
      "          1       0.45      0.51      0.48      5557\n",
      "          2       0.74      0.64      0.68     15819\n",
      "          3       0.48      0.52      0.50      6537\n",
      "          4       0.39      0.50      0.43      1859\n",
      "\n",
      "avg / total       0.60      0.57      0.58     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_pip_ngram = Pipeline([(\"counts\", CountVectorizer(ngram_range=(1, 3))),\n",
    "                      (\"classifier\", MultinomialNB())])\n",
    "report(naive_pip_ngram, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test usando Random Forest\n",
    "\n",
    "Por ser um algoritmo de aprendizagem de máquina que tradicionalmente tem apresentado bons resultados nos mais diversos segmentos, inclusive no campo de processamento de linguagem natural, decidi testá-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.6321927463795975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.36      0.40      1454\n",
      "          1       0.54      0.45      0.49      5509\n",
      "          2       0.70      0.81      0.75     15805\n",
      "          3       0.55      0.48      0.51      6570\n",
      "          4       0.50      0.39      0.44      1874\n",
      "\n",
      "avg / total       0.62      0.63      0.62     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pip = Pipeline([(\"counts\", CountVectorizer()),\n",
    "                      (\"classifier\", RandomForestClassifier(n_estimators=200, random_state=0))])\n",
    "report(rf_pip, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.640234525182622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.36      0.40      1454\n",
      "          1       0.56      0.44      0.49      5509\n",
      "          2       0.70      0.84      0.76     15805\n",
      "          3       0.57      0.47      0.52      6570\n",
      "          4       0.53      0.38      0.45      1874\n",
      "\n",
      "avg / total       0.63      0.64      0.63     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pip2 = Pipeline([(\"counts\", TfidfVectorizer()),\n",
    "                      (\"classifier\", RandomForestClassifier(n_estimators=200, random_state=0))])\n",
    "report(rf_pip2, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Entre os classificadores testados pude constatar que o Random Forest aprensentou melhor desempenho, principalmente quando a contagem é feita utilizando TF-IDF. Podemos observar isso pelos valores da acurácia, 64%; precision 63% e recall, 64% no melhor caso testado. \n",
    "Além disso, é possível perceber que a classe das sentenças neutras (2) é classificada com melhor precisão e tem um maior recall em relação aos outros tipos de sentenças, provavelmente pelo fato de ter mais sentenças pertencentes a está classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planos futuros e possíveis melhorias\n",
    "\n",
    "Como sugestão de melhorias, poderia ser testados ajustes de hiper parâmetros usando Grid Search, utilizar outros algoritmos de aprendizagem de máquina como SVM e MLP e, talvez, uma análise mais profunda dos dados com o objetivos de encontrar padrões ou fazer um melhor pré-processamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste usando Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.6357490708701782\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.27      0.36      1440\n",
      "          1       0.53      0.36      0.43      5557\n",
      "          2       0.67      0.89      0.76     15819\n",
      "          3       0.59      0.43      0.50      6537\n",
      "          4       0.60      0.33      0.43      1859\n",
      "\n",
      "avg / total       0.62      0.64      0.61     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pip = Pipeline([(\"counts\", CountVectorizer()),\n",
    "                      (\"classifier\", LogisticRegression())])\n",
    "report(lr_pip, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.6231897987953351\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.15      0.25      1440\n",
      "          1       0.52      0.32      0.40      5557\n",
      "          2       0.65      0.90      0.75     15819\n",
      "          3       0.57      0.44      0.50      6537\n",
      "          4       0.64      0.21      0.32      1859\n",
      "\n",
      "avg / total       0.61      0.62      0.59     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pip_tdif = Pipeline([(\"counts\", TfidfVectorizer()),\n",
    "                      (\"classifier\", LogisticRegression())])\n",
    "report(lr_pip_tdif, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.6136742278610791\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.26      0.35      1440\n",
      "          1       0.55      0.33      0.41      5557\n",
      "          2       0.63      0.89      0.74     15819\n",
      "          3       0.58      0.35      0.44      6537\n",
      "          4       0.56      0.28      0.37      1859\n",
      "\n",
      "avg / total       0.60      0.61      0.58     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pip_2gran = Pipeline([(\"counts\", CountVectorizer(min_df=5, ngram_range=(2, 2))),\n",
    "                      (\"classifier\", LogisticRegression())])\n",
    "report(lr_pip_2gran, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.6500704857106241\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.33      0.40      1440\n",
      "          1       0.56      0.42      0.48      5557\n",
      "          2       0.70      0.86      0.77     15819\n",
      "          3       0.60      0.48      0.53      6537\n",
      "          4       0.56      0.38      0.45      1859\n",
      "\n",
      "avg / total       0.63      0.65      0.63     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pip_ngran = Pipeline([(\"counts\", CountVectorizer(min_df=5, ngram_range=(1, 3))),\n",
    "                      (\"classifier\", LogisticRegression(C=1))])\n",
    "report(lr_pip_ngran, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.6500704857106241\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.33      0.40      1440\n",
      "          1       0.56      0.42      0.48      5557\n",
      "          2       0.70      0.86      0.77     15819\n",
      "          3       0.60      0.48      0.53      6537\n",
      "          4       0.56      0.38      0.45      1859\n",
      "\n",
      "avg / total       0.63      0.65      0.63     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pip_ngran = Pipeline([(\"counts\", CountVectorizer(min_df=5, ngram_range=(1, 3))),\n",
    "                      (\"classifier\", LogisticRegression(C=1))])\n",
    "report(lr_pip_ngran, x_train, x_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
